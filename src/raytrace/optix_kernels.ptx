//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-37061995
// Cuda compilation tools, release 13.1, V13.1.115
// Based on NVVM 7.0.1
//

.version 9.1
.target sm_86
.address_size 64

	// .globl	__raygen__visibility
.const .align 8 .b8 params[208];

.visible .entry __raygen__visibility()
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<11>;
	.reg .b32 	%r<75>;
	.reg .b64 	%rd<10>;


	// begin inline asm
	call (%r2), _optix_get_launch_index_x, ();
	// end inline asm
	ld.const.u32 	%r3, [params+16];
	setp.ge.s32 	%p1, %r2, %r3;
	@%p1 bra 	$L__BB0_2;

	ld.const.u64 	%rd2, [params];
	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r2, 36;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f1, [%rd5];
	ld.global.f32 	%f2, [%rd5+4];
	ld.global.f32 	%f3, [%rd5+8];
	ld.global.f32 	%f4, [%rd5+12];
	ld.global.f32 	%f5, [%rd5+16];
	ld.global.f32 	%f6, [%rd5+20];
	ld.global.u32 	%r48, [%rd5+32];
	ld.global.f32 	%f10, [%rd5+24];
	setp.lt.ftz.f32 	%p2, %f10, 0f38D1B717;
	selp.f32 	%f7, 0f38D1B717, %f10, %p2;
	ld.const.u64 	%rd1, [params+24];
	ld.global.f32 	%f8, [%rd5+28];
	mov.f32 	%f9, 0f00000000;
	mov.u32 	%r37, 255;
	mov.u32 	%r40, 1;
	mov.u32 	%r42, 6;
	mov.u32 	%r43, 1900671690;
	mov.u32 	%r44, -1;
	mov.u32 	%r74, 0;
	// begin inline asm
	call(%r4,%r5,%r6,%r7,%r8,%r9,%r10,%r11,%r12,%r13,%r14,%r15,%r16,%r17,%r18,%r19,%r20,%r21,%r22,%r23,%r24,%r25,%r26,%r27,%r28,%r29,%r30,%r31,%r32,%r33,%r34,%r35),_optix_trace_typed_32,(%r74,%rd1,%f1,%f2,%f3,%f4,%f5,%f6,%f7,%f8,%f9,%r37,%r74,%r74,%r40,%r74,%r42,%r43,%r44,%r74,%r74,%r74,%r48,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74,%r74);
	// end inline asm
	ld.const.u64 	%rd6, [params+8];
	cvta.to.global.u64 	%rd7, %rd6;
	mul.wide.s32 	%rd8, %r2, 20;
	add.s64 	%rd9, %rd7, %rd8;
	st.global.u32 	[%rd9], %r4;
	st.global.u32 	[%rd9+4], %r5;
	st.global.u32 	[%rd9+8], %r6;
	st.global.u32 	[%rd9+12], %r7;
	st.global.u32 	[%rd9+16], %r8;

$L__BB0_2:
	ret;

}
	// .globl	__anyhit__visibility
.visible .entry __anyhit__visibility()
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<5>;


	// begin inline asm
	call (%r1), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r3, 5;
	// begin inline asm
	call (%r2), _optix_get_payload, (%r3);
	// end inline asm
	ld.const.u64 	%rd1, [params+32];
	cvta.to.global.u64 	%rd2, %rd1;
	mul.wide.s32 	%rd3, %r1, 48;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.u32 	%r4, [%rd4+16];
	setp.ne.s32 	%p1, %r4, %r2;
	@%p1 bra 	$L__BB1_2;

	// begin inline asm
	call _optix_ignore_intersection, ();
	// end inline asm

$L__BB1_2:
	ret;

}
	// .globl	__closesthit__visibility
.visible .entry __closesthit__visibility()
{
	.reg .f32 	%f<2>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<5>;


	// begin inline asm
	call (%r1), _optix_read_primitive_idx, ();
	// end inline asm
	// begin inline asm
	call (%f1), _optix_get_ray_tmax, ();
	// end inline asm
	ld.const.u64 	%rd1, [params+32];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.b32 	%r3, %f1;
	mov.u32 	%r2, 0;
	// begin inline asm
	call _optix_set_payload, (%r2, %r3);
	// end inline asm
	mov.u32 	%r4, 1;
	// begin inline asm
	call _optix_set_payload, (%r4, %r1);
	// end inline asm
	mul.wide.s32 	%rd3, %r1, 48;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.u32 	%r7, [%rd4];
	mov.u32 	%r6, 2;
	// begin inline asm
	call _optix_set_payload, (%r6, %r7);
	// end inline asm
	ld.global.u32 	%r9, [%rd4+4];
	mov.u32 	%r8, 3;
	// begin inline asm
	call _optix_set_payload, (%r8, %r9);
	// end inline asm
	ld.global.u32 	%r11, [%rd4+8];
	mov.u32 	%r10, 4;
	// begin inline asm
	call _optix_set_payload, (%r10, %r11);
	// end inline asm
	ret;

}
	// .globl	__miss__visibility
.visible .entry __miss__visibility()
{
	.reg .b32 	%r<11>;


	mov.u32 	%r10, 0;
	mov.u32 	%r2, 1900671690;
	// begin inline asm
	call _optix_set_payload, (%r10, %r2);
	// end inline asm
	mov.u32 	%r3, 1;
	mov.u32 	%r4, -1;
	// begin inline asm
	call _optix_set_payload, (%r3, %r4);
	// end inline asm
	mov.u32 	%r5, 2;
	// begin inline asm
	call _optix_set_payload, (%r5, %r10);
	// end inline asm
	mov.u32 	%r7, 3;
	// begin inline asm
	call _optix_set_payload, (%r7, %r10);
	// end inline asm
	mov.u32 	%r9, 4;
	// begin inline asm
	call _optix_set_payload, (%r9, %r10);
	// end inline asm
	ret;

}
	// .globl	__raygen__cluster_visibility
.visible .entry __raygen__cluster_visibility()
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<133>;
	.reg .b32 	%r<333>;
	.reg .b64 	%rd<50>;


	// begin inline asm
	call (%r57), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r58), _optix_get_launch_index_y, ();
	// end inline asm
	ld.const.u32 	%r59, [params+48];
	setp.ge.s32 	%p1, %r57, %r59;
	ld.const.u32 	%r60, [params+64];
	setp.ge.s32 	%p2, %r58, %r60;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB4_29;

	ld.const.u64 	%rd13, [params+40];
	cvta.to.global.u64 	%rd14, %rd13;
	mul.wide.s32 	%rd15, %r57, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.const.u64 	%rd17, [params+96];
	cvta.to.global.u64 	%rd1, %rd17;
	ld.global.u32 	%r3, [%rd16];
	ld.const.u64 	%rd18, [params+56];
	cvta.to.global.u64 	%rd19, %rd18;
	mul.wide.s32 	%rd20, %r58, 4;
	add.s64 	%rd21, %rd19, %rd20;
	ld.const.u64 	%rd22, [params+72];
	cvta.to.global.u64 	%rd23, %rd22;
	ld.global.u32 	%r61, [%rd21];
	mul.wide.s32 	%rd24, %r61, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.u32 	%r4, [%rd25];
	ld.global.u32 	%r5, [%rd25+4];
	setp.le.s32 	%p4, %r5, %r4;
	@%p4 bra 	$L__BB4_29;

	ld.const.u64 	%rd26, [params+80];
	cvta.to.global.u64 	%rd2, %rd26;
	mul.wide.s32 	%rd27, %r3, 52;
	add.s64 	%rd3, %rd1, %rd27;
	ld.const.u64 	%rd4, [params+24];
	ld.const.u64 	%rd28, [params+128];
	cvta.to.global.u64 	%rd5, %rd28;
	ld.const.u32 	%r6, [params+136];
	ld.const.u64 	%rd29, [params+120];
	cvta.to.global.u64 	%rd6, %rd29;
	sub.s32 	%r62, %r5, %r4;
	and.b32  	%r63, %r62, 1;
	setp.eq.b32 	%p5, %r63, 1;
	mov.pred 	%p6, 0;
	xor.pred  	%p7, %p5, %p6;
	not.pred 	%p8, %p7;
	@%p8 bra 	$L__BB4_11;
	bra.uni 	$L__BB4_3;

$L__BB4_11:
	mov.u32 	%r317, %r4;
	bra.uni 	$L__BB4_12;

$L__BB4_3:
	mul.wide.s32 	%rd30, %r4, 4;
	add.s64 	%rd31, %rd2, %rd30;
	ld.global.u32 	%r7, [%rd31];
	mul.wide.s32 	%rd32, %r7, 52;
	add.s64 	%rd33, %rd1, %rd32;
	add.s64 	%rd7, %rd33, 28;
	ld.global.u32 	%r65, [%rd3+28];
	ld.global.u32 	%r66, [%rd33+28];
	setp.eq.s32 	%p9, %r66, %r65;
	@%p9 bra 	$L__BB4_10;

	ld.global.f32 	%f1, [%rd3+12];
	ld.global.f32 	%f2, [%rd7+-28];
	ld.global.f32 	%f3, [%rd3+16];
	ld.global.f32 	%f4, [%rd7+-24];
	mul.ftz.f32 	%f58, %f4, %f3;
	fma.rn.ftz.f32 	%f59, %f2, %f1, %f58;
	ld.global.f32 	%f5, [%rd3+20];
	ld.global.f32 	%f6, [%rd7+-20];
	fma.rn.ftz.f32 	%f60, %f6, %f5, %f59;
	ld.global.f32 	%f61, [%rd3+24];
	add.ftz.f32 	%f62, %f61, 0f3C23D70A;
	setp.le.ftz.f32 	%p10, %f60, %f62;
	@%p10 bra 	$L__BB4_10;

	ld.global.f32 	%f7, [%rd3];
	ld.global.f32 	%f8, [%rd7+-16];
	ld.global.f32 	%f9, [%rd7+-12];
	ld.global.f32 	%f10, [%rd3+4];
	mul.ftz.f32 	%f63, %f10, %f9;
	fma.rn.ftz.f32 	%f64, %f7, %f8, %f63;
	ld.global.f32 	%f11, [%rd7+-8];
	ld.global.f32 	%f12, [%rd3+8];
	fma.rn.ftz.f32 	%f65, %f12, %f11, %f64;
	ld.global.f32 	%f66, [%rd7+-4];
	add.ftz.f32 	%f67, %f66, 0f3C23D70A;
	setp.le.ftz.f32 	%p11, %f65, %f67;
	@%p11 bra 	$L__BB4_10;

	add.ftz.f32 	%f13, %f7, %f1;
	add.ftz.f32 	%f68, %f2, %f8;
	sub.ftz.f32 	%f14, %f68, %f13;
	add.ftz.f32 	%f69, %f4, %f9;
	add.ftz.f32 	%f15, %f10, %f3;
	sub.ftz.f32 	%f16, %f69, %f15;
	add.ftz.f32 	%f70, %f6, %f11;
	add.ftz.f32 	%f17, %f12, %f5;
	sub.ftz.f32 	%f18, %f70, %f17;
	mul.ftz.f32 	%f71, %f16, %f16;
	fma.rn.ftz.f32 	%f72, %f14, %f14, %f71;
	fma.rn.ftz.f32 	%f73, %f18, %f18, %f72;
	sqrt.approx.ftz.f32 	%f19, %f73;
	setp.lt.ftz.f32 	%p12, %f19, 0f38D1B717;
	@%p12 bra 	$L__BB4_10;

	div.approx.ftz.f32 	%f77, %f14, %f19;
	add.ftz.f32 	%f81, %f19, 0fB8D1B717;
	div.approx.ftz.f32 	%f79, %f18, %f19;
	div.approx.ftz.f32 	%f78, %f16, %f19;
	mov.f32 	%f82, 0f00000000;
	mov.u32 	%r103, 255;
	mov.u32 	%r106, 1;
	mov.u32 	%r108, 6;
	mov.u32 	%r114, -1;
	mov.u32 	%r140, 0;
	// begin inline asm
	call(%r310,%r328,%r307,%r308,%r309,%r75,%r76,%r77,%r78,%r79,%r80,%r81,%r82,%r83,%r84,%r85,%r86,%r87,%r88,%r89,%r90,%r91,%r92,%r93,%r94,%r95,%r96,%r97,%r98,%r99,%r100,%r101),_optix_trace_typed_32,(%r140,%rd4,%f13,%f15,%f17,%f77,%f78,%f79,%f82,%f81,%f82,%r103,%r106,%r140,%r106,%r140,%r108,%r141,%r142,%r143,%r144,%r145,%r114,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140,%r140);
	// end inline asm
	setp.ne.s32 	%p13, %r328, -1;
	@%p13 bra 	$L__BB4_10;

	mov.u32 	%r328, -1;
	atom.global.add.u32 	%r13, [%rd5], 1;
	setp.ge.s32 	%p14, %r13, %r6;
	@%p14 bra 	$L__BB4_10;

	mov.u32 	%r328, -1;
	mul.wide.s32 	%rd35, %r13, 8;
	add.s64 	%rd36, %rd6, %rd35;
	st.global.u32 	[%rd36], %r3;
	st.global.u32 	[%rd36+4], %r7;

$L__BB4_10:
	add.s32 	%r317, %r4, 1;

$L__BB4_12:
	add.s32 	%r149, %r4, 1;
	setp.eq.s32 	%p15, %r5, %r149;
	@%p15 bra 	$L__BB4_29;

	mul.wide.s32 	%rd37, %r317, 4;
	add.s64 	%rd38, %rd2, %rd37;
	add.s64 	%rd49, %rd38, 4;

$L__BB4_14:
	ld.global.u32 	%r32, [%rd49+-4];
	mul.wide.s32 	%rd39, %r32, 52;
	add.s64 	%rd40, %rd1, %rd39;
	add.s64 	%rd10, %rd40, 28;
	ld.global.u32 	%r150, [%rd3+28];
	ld.global.u32 	%r151, [%rd40+28];
	setp.eq.s32 	%p16, %r151, %r150;
	@%p16 bra 	$L__BB4_21;

	ld.global.f32 	%f20, [%rd3+12];
	ld.global.f32 	%f21, [%rd10+-28];
	ld.global.f32 	%f22, [%rd3+16];
	ld.global.f32 	%f23, [%rd10+-24];
	mul.ftz.f32 	%f83, %f23, %f22;
	fma.rn.ftz.f32 	%f84, %f21, %f20, %f83;
	ld.global.f32 	%f24, [%rd3+20];
	ld.global.f32 	%f25, [%rd10+-20];
	fma.rn.ftz.f32 	%f85, %f25, %f24, %f84;
	ld.global.f32 	%f86, [%rd3+24];
	add.ftz.f32 	%f87, %f86, 0f3C23D70A;
	setp.le.ftz.f32 	%p17, %f85, %f87;
	@%p17 bra 	$L__BB4_21;

	ld.global.f32 	%f26, [%rd3];
	ld.global.f32 	%f27, [%rd10+-16];
	ld.global.f32 	%f28, [%rd10+-12];
	ld.global.f32 	%f29, [%rd3+4];
	mul.ftz.f32 	%f88, %f29, %f28;
	fma.rn.ftz.f32 	%f89, %f26, %f27, %f88;
	ld.global.f32 	%f30, [%rd10+-8];
	ld.global.f32 	%f31, [%rd3+8];
	fma.rn.ftz.f32 	%f90, %f31, %f30, %f89;
	ld.global.f32 	%f91, [%rd10+-4];
	add.ftz.f32 	%f92, %f91, 0f3C23D70A;
	setp.le.ftz.f32 	%p18, %f90, %f92;
	@%p18 bra 	$L__BB4_21;

	add.ftz.f32 	%f32, %f26, %f20;
	add.ftz.f32 	%f93, %f21, %f27;
	sub.ftz.f32 	%f33, %f93, %f32;
	add.ftz.f32 	%f94, %f23, %f28;
	add.ftz.f32 	%f34, %f29, %f22;
	sub.ftz.f32 	%f35, %f94, %f34;
	add.ftz.f32 	%f95, %f25, %f30;
	add.ftz.f32 	%f36, %f31, %f24;
	sub.ftz.f32 	%f37, %f95, %f36;
	mul.ftz.f32 	%f96, %f35, %f35;
	fma.rn.ftz.f32 	%f97, %f33, %f33, %f96;
	fma.rn.ftz.f32 	%f98, %f37, %f37, %f97;
	sqrt.approx.ftz.f32 	%f38, %f98;
	setp.lt.ftz.f32 	%p19, %f38, 0f38D1B717;
	@%p19 bra 	$L__BB4_21;

	div.approx.ftz.f32 	%f102, %f33, %f38;
	add.ftz.f32 	%f106, %f38, 0fB8D1B717;
	div.approx.ftz.f32 	%f104, %f37, %f38;
	div.approx.ftz.f32 	%f103, %f35, %f38;
	mov.f32 	%f107, 0f00000000;
	mov.u32 	%r185, 255;
	mov.u32 	%r188, 1;
	mov.u32 	%r190, 6;
	mov.u32 	%r196, -1;
	mov.u32 	%r222, 0;
	// begin inline asm
	call(%r310,%r328,%r307,%r308,%r309,%r157,%r158,%r159,%r160,%r161,%r162,%r163,%r164,%r165,%r166,%r167,%r168,%r169,%r170,%r171,%r172,%r173,%r174,%r175,%r176,%r177,%r178,%r179,%r180,%r181,%r182,%r183),_optix_trace_typed_32,(%r222,%rd4,%f32,%f34,%f36,%f102,%f103,%f104,%f107,%f106,%f107,%r185,%r188,%r222,%r188,%r222,%r190,%r310,%r328,%r307,%r308,%r309,%r196,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222,%r222);
	// end inline asm
	setp.ne.s32 	%p20, %r328, -1;
	@%p20 bra 	$L__BB4_21;

	mov.u32 	%r328, -1;
	atom.global.add.u32 	%r38, [%rd5], 1;
	setp.ge.s32 	%p21, %r38, %r6;
	@%p21 bra 	$L__BB4_21;

	mov.u32 	%r328, -1;
	mul.wide.s32 	%rd42, %r38, 8;
	add.s64 	%rd43, %rd6, %rd42;
	st.global.u32 	[%rd43], %r3;
	st.global.u32 	[%rd43+4], %r32;

$L__BB4_21:
	ld.global.u32 	%r44, [%rd49];
	mul.wide.s32 	%rd44, %r44, 52;
	add.s64 	%rd45, %rd1, %rd44;
	add.s64 	%rd11, %rd45, 28;
	ld.global.u32 	%r225, [%rd3+28];
	ld.global.u32 	%r226, [%rd45+28];
	setp.eq.s32 	%p22, %r226, %r225;
	@%p22 bra 	$L__BB4_28;

	ld.global.f32 	%f39, [%rd3+12];
	ld.global.f32 	%f40, [%rd11+-28];
	ld.global.f32 	%f41, [%rd3+16];
	ld.global.f32 	%f42, [%rd11+-24];
	mul.ftz.f32 	%f108, %f42, %f41;
	fma.rn.ftz.f32 	%f109, %f40, %f39, %f108;
	ld.global.f32 	%f43, [%rd3+20];
	ld.global.f32 	%f44, [%rd11+-20];
	fma.rn.ftz.f32 	%f110, %f44, %f43, %f109;
	ld.global.f32 	%f111, [%rd3+24];
	add.ftz.f32 	%f112, %f111, 0f3C23D70A;
	setp.le.ftz.f32 	%p23, %f110, %f112;
	@%p23 bra 	$L__BB4_28;

	ld.global.f32 	%f45, [%rd3];
	ld.global.f32 	%f46, [%rd11+-16];
	ld.global.f32 	%f47, [%rd11+-12];
	ld.global.f32 	%f48, [%rd3+4];
	mul.ftz.f32 	%f113, %f48, %f47;
	fma.rn.ftz.f32 	%f114, %f45, %f46, %f113;
	ld.global.f32 	%f49, [%rd11+-8];
	ld.global.f32 	%f50, [%rd3+8];
	fma.rn.ftz.f32 	%f115, %f50, %f49, %f114;
	ld.global.f32 	%f116, [%rd11+-4];
	add.ftz.f32 	%f117, %f116, 0f3C23D70A;
	setp.le.ftz.f32 	%p24, %f115, %f117;
	@%p24 bra 	$L__BB4_28;

	add.ftz.f32 	%f51, %f45, %f39;
	add.ftz.f32 	%f118, %f40, %f46;
	sub.ftz.f32 	%f52, %f118, %f51;
	add.ftz.f32 	%f119, %f42, %f47;
	add.ftz.f32 	%f53, %f48, %f41;
	sub.ftz.f32 	%f54, %f119, %f53;
	add.ftz.f32 	%f120, %f44, %f49;
	add.ftz.f32 	%f55, %f50, %f43;
	sub.ftz.f32 	%f56, %f120, %f55;
	mul.ftz.f32 	%f121, %f54, %f54;
	fma.rn.ftz.f32 	%f122, %f52, %f52, %f121;
	fma.rn.ftz.f32 	%f123, %f56, %f56, %f122;
	sqrt.approx.ftz.f32 	%f57, %f123;
	setp.lt.ftz.f32 	%p25, %f57, 0f38D1B717;
	@%p25 bra 	$L__BB4_28;

	div.approx.ftz.f32 	%f127, %f52, %f57;
	add.ftz.f32 	%f131, %f57, 0fB8D1B717;
	div.approx.ftz.f32 	%f129, %f56, %f57;
	div.approx.ftz.f32 	%f128, %f54, %f57;
	mov.f32 	%f132, 0f00000000;
	mov.u32 	%r260, 255;
	mov.u32 	%r263, 1;
	mov.u32 	%r265, 6;
	mov.u32 	%r271, -1;
	mov.u32 	%r297, 0;
	// begin inline asm
	call(%r310,%r328,%r307,%r308,%r309,%r232,%r233,%r234,%r235,%r236,%r237,%r238,%r239,%r240,%r241,%r242,%r243,%r244,%r245,%r246,%r247,%r248,%r249,%r250,%r251,%r252,%r253,%r254,%r255,%r256,%r257,%r258),_optix_trace_typed_32,(%r297,%rd4,%f51,%f53,%f55,%f127,%f128,%f129,%f132,%f131,%f132,%r260,%r263,%r297,%r263,%r297,%r265,%r310,%r328,%r307,%r308,%r309,%r271,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297,%r297);
	// end inline asm
	setp.ne.s32 	%p26, %r328, -1;
	@%p26 bra 	$L__BB4_28;

	mov.u32 	%r328, -1;
	atom.global.add.u32 	%r50, [%rd5], 1;
	setp.ge.s32 	%p27, %r50, %r6;
	@%p27 bra 	$L__BB4_28;

	mov.u32 	%r328, -1;
	mul.wide.s32 	%rd47, %r50, 8;
	add.s64 	%rd48, %rd6, %rd47;
	st.global.u32 	[%rd48], %r3;
	st.global.u32 	[%rd48+4], %r44;

$L__BB4_28:
	add.s64 	%rd49, %rd49, 8;
	add.s32 	%r317, %r317, 2;
	setp.lt.s32 	%p28, %r317, %r5;
	@%p28 bra 	$L__BB4_14;

$L__BB4_29:
	ret;

}
	// .globl	__raygen__direct_lighting
.visible .entry __raygen__direct_lighting()
{
	.local .align 16 .b8 	__local_depot5[96];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<69>;
	.reg .f32 	%f<315>;
	.reg .b32 	%r<126>;
	.reg .b64 	%rd<95>;


	mov.u64 	%SPL, __local_depot5;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd2, %SPL, 48;
	add.u64 	%rd3, %SPL, 64;
	add.u64 	%rd4, %SPL, 80;
	// begin inline asm
	call (%r28), _optix_get_launch_index_x, ();
	// end inline asm
	ld.const.u32 	%r29, [params+192];
	setp.ge.s32 	%p1, %r28, %r29;
	@%p1 bra 	$L__BB5_72;

	ld.const.u64 	%rd37, [params+144];
	cvta.to.global.u64 	%rd38, %rd37;
	cvt.s64.s32 	%rd5, %r28;
	mul.wide.s32 	%rd39, %r28, 40;
	add.s64 	%rd6, %rd38, %rd39;
	ld.global.f32 	%f1, [%rd6];
	ld.global.f32 	%f2, [%rd6+4];
	ld.global.f32 	%f3, [%rd6+8];
	ld.global.f32 	%f4, [%rd6+12];
	ld.global.f32 	%f5, [%rd6+16];
	ld.global.f32 	%f6, [%rd6+20];
	ld.global.u32 	%r2, [%rd6+32];
	setp.lt.s32 	%p2, %r2, 0;
	ld.const.u32 	%r30, [params+200];
	setp.ge.s32 	%p3, %r2, %r30;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB5_72;

	ld.const.u64 	%rd40, [params+176];
	cvta.to.global.u64 	%rd41, %rd40;
	ld.global.u32 	%r31, [%rd6+24];
	mul.wide.s32 	%rd42, %r31, 52;
	add.s64 	%rd43, %rd41, %rd42;
	add.s64 	%rd7, %rd43, 12;
	ld.global.u32 	%r3, [%rd43+12];
	st.local.v2.f32 	[%rd1], {%f4, %f5};
	st.local.f32 	[%rd1+8], %f6;
	setp.lt.s32 	%p5, %r3, 2;
	@%p5 bra 	$L__BB5_4;

	ld.global.f32 	%f91, [%rd7+4];
	ld.global.f32 	%f92, [%rd7+12];
	ld.global.f32 	%f93, [%rd7+8];
	st.local.f32 	[%rd1+12], %f91;
	ld.global.f32 	%f94, [%rd7+20];
	ld.global.f32 	%f95, [%rd7+16];
	ld.global.f32 	%f96, [%rd7+24];
	st.local.v4.f32 	[%rd1+16], {%f93, %f92, %f95, %f94};
	ld.global.f32 	%f97, [%rd7+36];
	ld.global.f32 	%f98, [%rd7+32];
	ld.global.f32 	%f99, [%rd7+28];
	st.local.v4.f32 	[%rd1+32], {%f96, %f99, %f98, %f97};

$L__BB5_4:
	ld.const.u64 	%rd44, [params+160];
	cvta.to.global.u64 	%rd45, %rd44;
	mul.wide.s32 	%rd46, %r2, 8;
	add.s64 	%rd9, %rd45, %rd46;
	ld.global.u32 	%r4, [%rd9+4];
	mov.f32 	%f100, 0f00000000;
	st.local.v4.f32 	[%rd2], {%f100, %f100, %f100, %f100};
	st.local.v4.f32 	[%rd3], {%f100, %f100, %f100, %f100};
	st.local.v4.f32 	[%rd4], {%f100, %f100, %f100, %f100};
	setp.lt.s32 	%p6, %r4, 1;
	@%p6 bra 	$L__BB5_45;

	ld.global.u32 	%r5, [%rd9];
	ld.const.u64 	%rd47, [params+168];
	cvta.to.global.u64 	%rd13, %rd47;
	ld.const.u32 	%r6, [params+196];
	ld.const.u64 	%rd48, [params+152];
	cvta.to.global.u64 	%rd14, %rd48;
	ld.const.u64 	%rd15, [params+24];
	add.s32 	%r7, %r3, -2;
	add.s32 	%r33, %r3, -1;
	and.b32  	%r8, %r33, 3;
	sub.s32 	%r9, %r33, %r8;
	mov.u32 	%r118, 0;

$L__BB5_6:
	add.s32 	%r34, %r118, %r5;
	mul.wide.s32 	%rd49, %r34, 4;
	add.s64 	%rd50, %rd13, %rd49;
	ld.global.u32 	%r11, [%rd50];
	setp.lt.s32 	%p7, %r11, 0;
	setp.ge.s32 	%p8, %r11, %r6;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB5_44;

	mul.wide.s32 	%rd51, %r11, 80;
	add.s64 	%rd52, %rd14, %rd51;
	add.s64 	%rd16, %rd52, 36;
	ld.global.u32 	%r12, [%rd52+36];
	setp.eq.s32 	%p10, %r12, 3;
	@%p10 bra 	$L__BB5_44;

	setp.eq.s32 	%p11, %r12, 5;
	@%p11 bra 	$L__BB5_44;

	ld.global.f32 	%f304, [%rd16+-36];
	sub.ftz.f32 	%f8, %f304, %f1;
	ld.global.f32 	%f305, [%rd16+-32];
	sub.ftz.f32 	%f10, %f305, %f2;
	ld.global.f32 	%f306, [%rd16+-28];
	sub.ftz.f32 	%f12, %f306, %f3;
	mul.ftz.f32 	%f101, %f10, %f10;
	fma.rn.ftz.f32 	%f102, %f8, %f8, %f101;
	fma.rn.ftz.f32 	%f13, %f12, %f12, %f102;
	setp.lt.ftz.f32 	%p12, %f13, 0f2EDBE6FF;
	@%p12 bra 	$L__BB5_44;

	sqrt.approx.ftz.f32 	%f14, %f13;
	rsqrt.approx.ftz.f32 	%f103, %f13;
	mul.ftz.f32 	%f15, %f8, %f103;
	mul.ftz.f32 	%f16, %f10, %f103;
	mul.ftz.f32 	%f17, %f12, %f103;
	mul.ftz.f32 	%f104, %f5, %f16;
	fma.rn.ftz.f32 	%f105, %f4, %f15, %f104;
	fma.rn.ftz.f32 	%f106, %f6, %f17, %f105;
	mov.f32 	%f307, 0f00000000;
	max.ftz.f32 	%f18, %f106, %f307;
	ld.global.f32 	%f19, [%rd16+32];
	ld.global.f32 	%f20, [%rd16+36];
	setp.gt.ftz.f32 	%p13, %f20, %f19;
	setp.gt.ftz.f32 	%p14, %f14, %f20;
	and.pred  	%p15, %p13, %p14;
	@%p15 bra 	$L__BB5_44;

	mov.f32 	%f108, 0f3F800000;
	max.ftz.f32 	%f109, %f14, %f108;
	ld.global.f32 	%f110, [%rd16+40];
	min.ftz.f32 	%f21, %f109, %f110;
	setp.eq.s32 	%p16, %r12, 0;
	@%p16 bra 	$L__BB5_25;

	setp.eq.s32 	%p17, %r12, 1;
	@%p17 bra 	$L__BB5_23;

	setp.ne.s32 	%p18, %r12, 2;
	@%p18 bra 	$L__BB5_44;

	ld.global.f32 	%f112, [%rd16+-12];
	ld.global.f32 	%f113, [%rd16+-8];
	mul.ftz.f32 	%f114, %f16, %f113;
	fma.rn.ftz.f32 	%f115, %f15, %f112, %f114;
	ld.global.f32 	%f116, [%rd16+-4];
	fma.rn.ftz.f32 	%f117, %f17, %f116, %f115;
	neg.ftz.f32 	%f22, %f117;
	ld.global.f32 	%f23, [%rd16+24];
	setp.ge.ftz.f32 	%p19, %f23, %f22;
	@%p19 bra 	$L__BB5_29;

	ld.global.f32 	%f119, [%rd16+12];
	ld.global.f32 	%f120, [%rd16+8];
	fma.rn.ftz.f32 	%f121, %f21, %f119, %f120;
	ld.global.f32 	%f122, [%rd16+16];
	mul.ftz.f32 	%f123, %f21, %f122;
	fma.rn.ftz.f32 	%f24, %f21, %f123, %f121;
	setp.leu.ftz.f32 	%p20, %f24, 0f00000000;
	mov.f32 	%f300, 0f00000000;
	@%p20 bra 	$L__BB5_17;

	rcp.approx.ftz.f32 	%f300, %f24;

$L__BB5_17:
	mul.ftz.f32 	%f307, %f300, %f22;
	ld.global.f32 	%f28, [%rd16+20];
	setp.ltu.ftz.f32 	%p21, %f28, %f22;
	@%p21 bra 	$L__BB5_29;

	sub.ftz.f32 	%f29, %f28, %f23;
	setp.leu.ftz.f32 	%p22, %f29, 0f00000000;
	mov.f32 	%f124, 0f00000000;
	mov.f32 	%f301, %f124;
	@%p22 bra 	$L__BB5_20;

	sub.ftz.f32 	%f125, %f22, %f23;
	div.approx.ftz.f32 	%f301, %f125, %f29;

$L__BB5_20:
	max.ftz.f32 	%f127, %f301, %f124;
	mov.f32 	%f128, 0f3F800000;
	min.ftz.f32 	%f302, %f127, %f128;
	ld.global.f32 	%f33, [%rd16+28];
	setp.eq.ftz.f32 	%p23, %f33, 0f00000000;
	setp.eq.ftz.f32 	%p24, %f33, 0f3F800000;
	or.pred  	%p25, %p23, %p24;
	@%p25 bra 	$L__BB5_22;

	lg2.approx.ftz.f32 	%f129, %f302;
	mul.ftz.f32 	%f130, %f33, %f129;
	ex2.approx.ftz.f32 	%f302, %f130;

$L__BB5_22:
	mul.ftz.f32 	%f307, %f307, %f302;
	bra.uni 	$L__BB5_29;

$L__BB5_25:
	ld.global.f32 	%f39, [%rd16+-12];
	ld.global.f32 	%f40, [%rd16+-8];
	mul.ftz.f32 	%f138, %f16, %f40;
	fma.rn.ftz.f32 	%f139, %f15, %f39, %f138;
	ld.global.f32 	%f41, [%rd16+-4];
	fma.rn.ftz.f32 	%f140, %f17, %f41, %f139;
	neg.ftz.f32 	%f141, %f140;
	mov.f32 	%f303, 0f00000000;
	max.ftz.f32 	%f42, %f141, %f303;
	setp.le.ftz.f32 	%p27, %f42, 0f00000000;
	setp.le.ftz.f32 	%p28, %f18, 0f00000000;
	or.pred  	%p29, %p28, %p27;
	@%p29 bra 	$L__BB5_29;

	setp.leu.ftz.f32 	%p30, %f13, 0f00000000;
	@%p30 bra 	$L__BB5_28;

	div.approx.ftz.f32 	%f303, %f42, %f13;

$L__BB5_28:
	fma.rn.ftz.f32 	%f304, %f39, 0f3D000000, %f304;
	fma.rn.ftz.f32 	%f305, %f40, 0f3D000000, %f305;
	fma.rn.ftz.f32 	%f306, %f41, 0f3D000000, %f306;
	mov.f32 	%f307, %f303;
	bra.uni 	$L__BB5_29;

$L__BB5_23:
	ld.global.f32 	%f132, [%rd16+12];
	ld.global.f32 	%f133, [%rd16+8];
	fma.rn.ftz.f32 	%f134, %f21, %f132, %f133;
	ld.global.f32 	%f135, [%rd16+16];
	mul.ftz.f32 	%f136, %f21, %f135;
	fma.rn.ftz.f32 	%f37, %f21, %f136, %f134;
	setp.leu.ftz.f32 	%p26, %f37, 0f00000000;
	@%p26 bra 	$L__BB5_29;

	rcp.approx.ftz.f32 	%f307, %f37;

$L__BB5_29:
	setp.leu.ftz.f32 	%p31, %f20, %f19;
	@%p31 bra 	$L__BB5_33;

	sub.ftz.f32 	%f52, %f20, %f19;
	setp.leu.ftz.f32 	%p32, %f52, 0f00000000;
	mov.f32 	%f143, 0f00000000;
	mov.f32 	%f308, %f143;
	@%p32 bra 	$L__BB5_32;

	sub.ftz.f32 	%f144, %f14, %f19;
	div.approx.ftz.f32 	%f308, %f144, %f52;

$L__BB5_32:
	max.ftz.f32 	%f146, %f308, %f143;
	mov.f32 	%f147, 0f3F800000;
	min.ftz.f32 	%f148, %f146, %f147;
	sub.ftz.f32 	%f149, %f147, %f148;
	mul.ftz.f32 	%f150, %f149, %f149;
	mul.ftz.f32 	%f151, %f149, %f150;
	fma.rn.ftz.f32 	%f152, %f149, 0f40C00000, 0fC1700000;
	fma.rn.ftz.f32 	%f153, %f149, %f152, 0f41200000;
	mul.ftz.f32 	%f154, %f151, %f153;
	mul.ftz.f32 	%f307, %f307, %f154;

$L__BB5_33:
	mul.ftz.f32 	%f57, %f18, %f307;
	setp.le.ftz.f32 	%p33, %f57, 0f00000000;
	@%p33 bra 	$L__BB5_44;

	sub.ftz.f32 	%f58, %f304, %f1;
	sub.ftz.f32 	%f59, %f305, %f2;
	mul.ftz.f32 	%f155, %f59, %f59;
	fma.rn.ftz.f32 	%f156, %f58, %f58, %f155;
	sub.ftz.f32 	%f60, %f306, %f3;
	fma.rn.ftz.f32 	%f157, %f60, %f60, %f156;
	sqrt.approx.ftz.f32 	%f61, %f157;
	setp.lt.ftz.f32 	%p34, %f61, 0f358637BD;
	@%p34 bra 	$L__BB5_44;

	rcp.approx.ftz.f32 	%f167, %f61;
	mul.ftz.f32 	%f161, %f58, %f167;
	mul.ftz.f32 	%f162, %f59, %f167;
	mul.ftz.f32 	%f163, %f60, %f167;
	mov.f32 	%f164, 0f3A83126F;
	mov.f32 	%f166, 0f00000000;
	mov.u32 	%r68, 255;
	mov.u32 	%r71, 1;
	mov.u32 	%r73, 6;
	mov.u32 	%r74, 1900671690;
	mov.u32 	%r79, -1;
	mov.u32 	%r105, 0;
	// begin inline asm
	call(%r35,%r36,%r37,%r38,%r39,%r40,%r41,%r42,%r43,%r44,%r45,%r46,%r47,%r48,%r49,%r50,%r51,%r52,%r53,%r54,%r55,%r56,%r57,%r58,%r59,%r60,%r61,%r62,%r63,%r64,%r65,%r66),_optix_trace_typed_32,(%r105,%rd15,%f1,%f2,%f3,%f161,%f162,%f163,%f164,%f61,%f166,%r68,%r105,%r105,%r71,%r105,%r73,%r74,%r79,%r105,%r105,%r105,%r79,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105,%r105);
	// end inline asm
	setp.ne.s32 	%p35, %r36, -1;
	setp.eq.s32 	%p36, %r36, -1;
	selp.f32 	%f62, 0f3F800000, 0f00000000, %p36;
	@%p35 bra 	$L__BB5_44;

	ld.global.f32 	%f63, [%rd16+-24];
	mul.ftz.f32 	%f168, %f57, %f62;
	ld.local.f32 	%f169, [%rd2];
	fma.rn.ftz.f32 	%f170, %f168, %f63, %f169;
	st.local.f32 	[%rd2], %f170;
	ld.global.f32 	%f64, [%rd16+-20];
	ld.local.f32 	%f171, [%rd3];
	fma.rn.ftz.f32 	%f172, %f168, %f64, %f171;
	st.local.f32 	[%rd3], %f172;
	ld.global.f32 	%f65, [%rd16+-16];
	ld.local.f32 	%f173, [%rd4];
	fma.rn.ftz.f32 	%f174, %f168, %f65, %f173;
	st.local.f32 	[%rd4], %f174;
	@%p5 bra 	$L__BB5_44;

	setp.lt.u32 	%p38, %r7, 3;
	mov.u32 	%r121, 1;
	@%p38 bra 	$L__BB5_40;

	mov.u32 	%r121, 1;
	mov.u32 	%r120, %r9;

$L__BB5_39:
	mul.wide.s32 	%rd54, %r121, 12;
	add.s64 	%rd55, %rd1, %rd54;
	ld.local.f32 	%f175, [%rd55];
	ld.local.f32 	%f176, [%rd55+4];
	mul.ftz.f32 	%f177, %f16, %f176;
	fma.rn.ftz.f32 	%f178, %f15, %f175, %f177;
	ld.local.f32 	%f179, [%rd55+8];
	fma.rn.ftz.f32 	%f180, %f17, %f179, %f178;
	mov.f32 	%f181, 0f00000000;
	max.ftz.f32 	%f182, %f180, %f181;
	mul.ftz.f32 	%f183, %f307, %f182;
	mul.ftz.f32 	%f184, %f62, %f183;
	mul.wide.s32 	%rd56, %r121, 4;
	add.s64 	%rd57, %rd2, %rd56;
	ld.local.f32 	%f185, [%rd57];
	fma.rn.ftz.f32 	%f186, %f63, %f184, %f185;
	st.local.f32 	[%rd57], %f186;
	add.s64 	%rd58, %rd3, %rd56;
	ld.local.f32 	%f187, [%rd58];
	fma.rn.ftz.f32 	%f188, %f184, %f64, %f187;
	st.local.f32 	[%rd58], %f188;
	add.s64 	%rd59, %rd4, %rd56;
	ld.local.f32 	%f189, [%rd59];
	fma.rn.ftz.f32 	%f190, %f184, %f65, %f189;
	st.local.f32 	[%rd59], %f190;
	ld.local.f32 	%f191, [%rd55+12];
	ld.local.f32 	%f192, [%rd55+16];
	mul.ftz.f32 	%f193, %f16, %f192;
	fma.rn.ftz.f32 	%f194, %f15, %f191, %f193;
	ld.local.f32 	%f195, [%rd55+20];
	fma.rn.ftz.f32 	%f196, %f17, %f195, %f194;
	max.ftz.f32 	%f197, %f196, %f181;
	mul.ftz.f32 	%f198, %f307, %f197;
	mul.ftz.f32 	%f199, %f62, %f198;
	ld.local.f32 	%f200, [%rd57+4];
	fma.rn.ftz.f32 	%f201, %f63, %f199, %f200;
	st.local.f32 	[%rd57+4], %f201;
	ld.local.f32 	%f202, [%rd58+4];
	fma.rn.ftz.f32 	%f203, %f199, %f64, %f202;
	st.local.f32 	[%rd58+4], %f203;
	ld.local.f32 	%f204, [%rd59+4];
	fma.rn.ftz.f32 	%f205, %f199, %f65, %f204;
	st.local.f32 	[%rd59+4], %f205;
	ld.local.f32 	%f206, [%rd55+24];
	ld.local.f32 	%f207, [%rd55+28];
	mul.ftz.f32 	%f208, %f16, %f207;
	fma.rn.ftz.f32 	%f209, %f15, %f206, %f208;
	ld.local.f32 	%f210, [%rd55+32];
	fma.rn.ftz.f32 	%f211, %f17, %f210, %f209;
	max.ftz.f32 	%f212, %f211, %f181;
	mul.ftz.f32 	%f213, %f307, %f212;
	mul.ftz.f32 	%f214, %f62, %f213;
	ld.local.f32 	%f215, [%rd57+8];
	fma.rn.ftz.f32 	%f216, %f63, %f214, %f215;
	st.local.f32 	[%rd57+8], %f216;
	ld.local.f32 	%f217, [%rd58+8];
	fma.rn.ftz.f32 	%f218, %f214, %f64, %f217;
	st.local.f32 	[%rd58+8], %f218;
	ld.local.f32 	%f219, [%rd59+8];
	fma.rn.ftz.f32 	%f220, %f214, %f65, %f219;
	st.local.f32 	[%rd59+8], %f220;
	ld.local.f32 	%f221, [%rd55+36];
	ld.local.f32 	%f222, [%rd55+40];
	mul.ftz.f32 	%f223, %f16, %f222;
	fma.rn.ftz.f32 	%f224, %f15, %f221, %f223;
	ld.local.f32 	%f225, [%rd55+44];
	fma.rn.ftz.f32 	%f226, %f17, %f225, %f224;
	max.ftz.f32 	%f227, %f226, %f181;
	mul.ftz.f32 	%f228, %f307, %f227;
	mul.ftz.f32 	%f229, %f62, %f228;
	ld.local.f32 	%f230, [%rd57+12];
	fma.rn.ftz.f32 	%f231, %f63, %f229, %f230;
	st.local.f32 	[%rd57+12], %f231;
	ld.local.f32 	%f232, [%rd58+12];
	fma.rn.ftz.f32 	%f233, %f229, %f64, %f232;
	st.local.f32 	[%rd58+12], %f233;
	ld.local.f32 	%f234, [%rd59+12];
	fma.rn.ftz.f32 	%f235, %f229, %f65, %f234;
	st.local.f32 	[%rd59+12], %f235;
	add.s32 	%r121, %r121, 4;
	add.s32 	%r120, %r120, -4;
	setp.ne.s32 	%p39, %r120, 0;
	@%p39 bra 	$L__BB5_39;

$L__BB5_40:
	setp.eq.s32 	%p40, %r8, 0;
	@%p40 bra 	$L__BB5_44;

	setp.eq.s32 	%p41, %r8, 1;
	mul.wide.s32 	%rd60, %r121, 12;
	add.s64 	%rd17, %rd1, %rd60;
	ld.local.f32 	%f236, [%rd17];
	ld.local.f32 	%f237, [%rd17+4];
	mul.ftz.f32 	%f238, %f16, %f237;
	fma.rn.ftz.f32 	%f239, %f15, %f236, %f238;
	ld.local.f32 	%f240, [%rd17+8];
	fma.rn.ftz.f32 	%f241, %f17, %f240, %f239;
	mov.f32 	%f242, 0f00000000;
	max.ftz.f32 	%f243, %f241, %f242;
	mul.ftz.f32 	%f244, %f307, %f243;
	mul.ftz.f32 	%f245, %f62, %f244;
	mul.wide.s32 	%rd61, %r121, 4;
	add.s64 	%rd18, %rd2, %rd61;
	ld.local.f32 	%f246, [%rd18];
	fma.rn.ftz.f32 	%f247, %f63, %f245, %f246;
	st.local.f32 	[%rd18], %f247;
	add.s64 	%rd19, %rd3, %rd61;
	ld.local.f32 	%f248, [%rd19];
	fma.rn.ftz.f32 	%f249, %f245, %f64, %f248;
	st.local.f32 	[%rd19], %f249;
	add.s64 	%rd20, %rd4, %rd61;
	ld.local.f32 	%f250, [%rd20];
	fma.rn.ftz.f32 	%f251, %f245, %f65, %f250;
	st.local.f32 	[%rd20], %f251;
	@%p41 bra 	$L__BB5_44;

	setp.eq.s32 	%p42, %r8, 2;
	ld.local.f32 	%f252, [%rd17+12];
	ld.local.f32 	%f253, [%rd17+16];
	mul.ftz.f32 	%f254, %f16, %f253;
	fma.rn.ftz.f32 	%f255, %f15, %f252, %f254;
	ld.local.f32 	%f256, [%rd17+20];
	fma.rn.ftz.f32 	%f257, %f17, %f256, %f255;
	max.ftz.f32 	%f259, %f257, %f242;
	mul.ftz.f32 	%f260, %f307, %f259;
	mul.ftz.f32 	%f261, %f62, %f260;
	ld.local.f32 	%f262, [%rd18+4];
	fma.rn.ftz.f32 	%f263, %f63, %f261, %f262;
	st.local.f32 	[%rd18+4], %f263;
	ld.local.f32 	%f264, [%rd19+4];
	fma.rn.ftz.f32 	%f265, %f261, %f64, %f264;
	st.local.f32 	[%rd19+4], %f265;
	ld.local.f32 	%f266, [%rd20+4];
	fma.rn.ftz.f32 	%f267, %f261, %f65, %f266;
	st.local.f32 	[%rd20+4], %f267;
	@%p42 bra 	$L__BB5_44;

	ld.local.f32 	%f268, [%rd17+24];
	ld.local.f32 	%f269, [%rd17+28];
	mul.ftz.f32 	%f270, %f16, %f269;
	fma.rn.ftz.f32 	%f271, %f15, %f268, %f270;
	ld.local.f32 	%f272, [%rd17+32];
	fma.rn.ftz.f32 	%f273, %f17, %f272, %f271;
	mov.f32 	%f274, 0f00000000;
	max.ftz.f32 	%f275, %f273, %f274;
	mul.ftz.f32 	%f276, %f307, %f275;
	mul.ftz.f32 	%f277, %f62, %f276;
	ld.local.f32 	%f278, [%rd18+8];
	fma.rn.ftz.f32 	%f279, %f63, %f277, %f278;
	st.local.f32 	[%rd18+8], %f279;
	ld.local.f32 	%f280, [%rd19+8];
	fma.rn.ftz.f32 	%f281, %f277, %f64, %f280;
	st.local.f32 	[%rd19+8], %f281;
	ld.local.f32 	%f282, [%rd20+8];
	fma.rn.ftz.f32 	%f283, %f277, %f65, %f282;
	st.local.f32 	[%rd20+8], %f283;

$L__BB5_44:
	add.s32 	%r118, %r118, 1;
	setp.lt.s32 	%p43, %r118, %r4;
	@%p43 bra 	$L__BB5_6;

$L__BB5_45:
	setp.lt.s32 	%p44, %r3, 1;
	@%p44 bra 	$L__BB5_72;

	ld.const.u64 	%rd62, [params+184];
	cvta.to.global.u64 	%rd21, %rd62;
	and.b32  	%r125, %r3, 3;
	add.s32 	%r109, %r3, -1;
	setp.lt.u32 	%p45, %r109, 3;
	mov.u32 	%r124, 0;
	@%p45 bra 	$L__BB5_65;

	sub.s32 	%r123, %r3, %r125;
	mov.u32 	%r124, 0;

$L__BB5_48:
	cvt.s64.s32 	%rd22, %r124;
	mul.wide.s32 	%rd63, %r124, 4;
	add.s64 	%rd23, %rd2, %rd63;
	ld.local.f32 	%f66, [%rd23];
	setp.gt.ftz.f32 	%p46, %f66, 0f00000000;
	add.s64 	%rd24, %rd3, %rd63;
	ld.local.f32 	%f67, [%rd24];
	setp.gt.ftz.f32 	%p47, %f67, 0f00000000;
	or.pred  	%p48, %p46, %p47;
	add.s64 	%rd25, %rd4, %rd63;
	@%p48 bra 	$L__BB5_50;
	bra.uni 	$L__BB5_49;

$L__BB5_50:
	ld.local.f32 	%f310, [%rd25];
	bra.uni 	$L__BB5_51;

$L__BB5_49:
	ld.local.f32 	%f310, [%rd25];
	setp.gt.ftz.f32 	%p49, %f310, 0f00000000;
	@%p49 bra 	$L__BB5_51;
	bra.uni 	$L__BB5_52;

$L__BB5_51:
	mul.lo.s64 	%rd64, %rd5, 52;
	add.s64 	%rd65, %rd21, %rd64;
	shl.b64 	%rd66, %rd22, 2;
	add.s64 	%rd67, %rd65, %rd66;
	atom.global.add.f32 	%f284, [%rd67], %f66;
	add.s64 	%rd68, %rd67, 16;
	atom.global.add.f32 	%f285, [%rd68], %f67;
	add.s64 	%rd69, %rd67, 32;
	atom.global.add.f32 	%f286, [%rd69], %f310;

$L__BB5_52:
	ld.local.f32 	%f71, [%rd23+4];
	setp.gt.ftz.f32 	%p50, %f71, 0f00000000;
	ld.local.f32 	%f72, [%rd24+4];
	setp.gt.ftz.f32 	%p51, %f72, 0f00000000;
	or.pred  	%p52, %p50, %p51;
	@%p52 bra 	$L__BB5_54;
	bra.uni 	$L__BB5_53;

$L__BB5_54:
	ld.local.f32 	%f311, [%rd25+4];
	bra.uni 	$L__BB5_55;

$L__BB5_53:
	ld.local.f32 	%f311, [%rd25+4];
	setp.gt.ftz.f32 	%p53, %f311, 0f00000000;
	@%p53 bra 	$L__BB5_55;
	bra.uni 	$L__BB5_56;

$L__BB5_55:
	cvt.u32.u64 	%r111, %rd22;
	add.s32 	%r112, %r111, 1;
	mul.lo.s64 	%rd70, %rd5, 52;
	add.s64 	%rd71, %rd21, %rd70;
	mul.wide.s32 	%rd72, %r112, 4;
	add.s64 	%rd73, %rd71, %rd72;
	atom.global.add.f32 	%f287, [%rd73], %f71;
	add.s64 	%rd74, %rd73, 16;
	atom.global.add.f32 	%f288, [%rd74], %f72;
	add.s64 	%rd75, %rd73, 32;
	atom.global.add.f32 	%f289, [%rd75], %f311;

$L__BB5_56:
	ld.local.f32 	%f76, [%rd23+8];
	setp.gt.ftz.f32 	%p54, %f76, 0f00000000;
	ld.local.f32 	%f77, [%rd24+8];
	setp.gt.ftz.f32 	%p55, %f77, 0f00000000;
	or.pred  	%p56, %p54, %p55;
	@%p56 bra 	$L__BB5_58;
	bra.uni 	$L__BB5_57;

$L__BB5_58:
	ld.local.f32 	%f312, [%rd25+8];
	bra.uni 	$L__BB5_59;

$L__BB5_57:
	ld.local.f32 	%f312, [%rd25+8];
	setp.gt.ftz.f32 	%p57, %f312, 0f00000000;
	@%p57 bra 	$L__BB5_59;
	bra.uni 	$L__BB5_60;

$L__BB5_59:
	cvt.u32.u64 	%r113, %rd22;
	add.s32 	%r114, %r113, 2;
	mul.lo.s64 	%rd76, %rd5, 52;
	add.s64 	%rd77, %rd21, %rd76;
	mul.wide.s32 	%rd78, %r114, 4;
	add.s64 	%rd79, %rd77, %rd78;
	atom.global.add.f32 	%f290, [%rd79], %f76;
	add.s64 	%rd80, %rd79, 16;
	atom.global.add.f32 	%f291, [%rd80], %f77;
	add.s64 	%rd81, %rd79, 32;
	atom.global.add.f32 	%f292, [%rd81], %f312;

$L__BB5_60:
	ld.local.f32 	%f81, [%rd23+12];
	setp.gt.ftz.f32 	%p58, %f81, 0f00000000;
	ld.local.f32 	%f82, [%rd24+12];
	setp.gt.ftz.f32 	%p59, %f82, 0f00000000;
	or.pred  	%p60, %p58, %p59;
	@%p60 bra 	$L__BB5_62;
	bra.uni 	$L__BB5_61;

$L__BB5_62:
	ld.local.f32 	%f313, [%rd25+12];
	bra.uni 	$L__BB5_63;

$L__BB5_61:
	ld.local.f32 	%f313, [%rd25+12];
	setp.gt.ftz.f32 	%p61, %f313, 0f00000000;
	@%p61 bra 	$L__BB5_63;
	bra.uni 	$L__BB5_64;

$L__BB5_63:
	cvt.u32.u64 	%r115, %rd22;
	add.s32 	%r116, %r115, 3;
	mul.lo.s64 	%rd82, %rd5, 52;
	add.s64 	%rd83, %rd21, %rd82;
	mul.wide.s32 	%rd84, %r116, 4;
	add.s64 	%rd85, %rd83, %rd84;
	atom.global.add.f32 	%f293, [%rd85], %f81;
	add.s64 	%rd86, %rd85, 16;
	atom.global.add.f32 	%f294, [%rd86], %f82;
	add.s64 	%rd87, %rd85, 32;
	atom.global.add.f32 	%f295, [%rd87], %f313;

$L__BB5_64:
	cvt.u32.u64 	%r117, %rd22;
	add.s32 	%r124, %r117, 4;
	add.s32 	%r123, %r123, -4;
	setp.ne.s32 	%p62, %r123, 0;
	@%p62 bra 	$L__BB5_48;

$L__BB5_65:
	setp.eq.s32 	%p63, %r125, 0;
	@%p63 bra 	$L__BB5_72;

	mul.wide.s32 	%rd94, %r124, 4;
	mul.lo.s64 	%rd88, %rd5, 52;
	add.s64 	%rd29, %rd21, %rd88;
	add.s64 	%rd27, %rd29, 32;
	add.s64 	%rd28, %rd29, 16;

$L__BB5_67:
	.pragma "nounroll";
	add.s64 	%rd89, %rd2, %rd94;
	ld.local.f32 	%f86, [%rd89];
	setp.gt.ftz.f32 	%p64, %f86, 0f00000000;
	add.s64 	%rd90, %rd3, %rd94;
	ld.local.f32 	%f87, [%rd90];
	setp.gt.ftz.f32 	%p65, %f87, 0f00000000;
	or.pred  	%p66, %p64, %p65;
	add.s64 	%rd31, %rd4, %rd94;
	@%p66 bra 	$L__BB5_69;
	bra.uni 	$L__BB5_68;

$L__BB5_69:
	ld.local.f32 	%f314, [%rd31];
	bra.uni 	$L__BB5_70;

$L__BB5_68:
	ld.local.f32 	%f314, [%rd31];
	setp.gt.ftz.f32 	%p67, %f314, 0f00000000;
	@%p67 bra 	$L__BB5_70;
	bra.uni 	$L__BB5_71;

$L__BB5_70:
	add.s64 	%rd91, %rd29, %rd94;
	atom.global.add.f32 	%f296, [%rd91], %f86;
	add.s64 	%rd92, %rd28, %rd94;
	atom.global.add.f32 	%f297, [%rd92], %f87;
	add.s64 	%rd93, %rd27, %rd94;
	atom.global.add.f32 	%f298, [%rd93], %f314;

$L__BB5_71:
	add.s32 	%r125, %r125, -1;
	add.s64 	%rd94, %rd94, 4;
	setp.ne.s32 	%p68, %r125, 0;
	@%p68 bra 	$L__BB5_67;

$L__BB5_72:
	ret;

}

